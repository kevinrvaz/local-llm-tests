{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657a0e44-5a9a-4d2a-ac93-19a9d8a8669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/kevinrvaz/.cache/huggingface/hub/models--TheBloke--Mistral-7B-OpenOrca-GGUF/snapshots/fbd9cd059e5fa0bba72a0abe8aea7e127d7994cb/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 514\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'open-orca_mistral-7b-openorca'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.environ[\"HOME\"], \".cache/huggingface/hub/models--TheBloke--Mistral-7B-OpenOrca-GGUF/snapshots/fbd9cd059e5fa0bba72a0abe8aea7e127d7994cb/mistral-7b-openorca.Q4_K_M.gguf\")\n",
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "model_kwargs = {\n",
    "  \"n_ctx\":4096,    # Context length to use\n",
    "  \"n_threads\":4,   # Number of CPU threads to use\n",
    "  \"n_gpu_layers\":0,# Number of model layers to offload to GPU. Set to 0 if only using CPU\n",
    "}\n",
    "\n",
    "## Instantiate model from downloaded file\n",
    "llm = Llama(model_path=model_path, **model_kwargs)\n",
    "\n",
    "## Generation kwargs\n",
    "generation_kwargs = {\n",
    "    \"max_tokens\":1000, # Max number of new tokens to generate\n",
    "    \"stop\":[\"<|endoftext|>\", \"</s>\"], # Text sequences to stop generation on\n",
    "    \"echo\":False, # Echo the prompt in the output\n",
    "    \"top_k\":2 # This is essentially greedy decoding, since the model will always return the highest-probability token. Set this value > 1 for sampling decoding\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52adf0d9-6c1a-46e2-889c-214dec20c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /   161 runs   (    0.01 ms per token, 80099.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5039.86 ms /    25 tokens (  201.59 ms per token,     4.96 tokens per second)\n",
      "llama_print_timings:        eval time =    9412.05 ms /   160 runs   (   58.83 ms per token,    17.00 tokens per second)\n",
      "llama_print_timings:       total time =   14503.14 ms /   185 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"gave the translation of the sentence delimited by triple quotes from english to hindi '''My name is Kevin'''\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e55efcc-6933-42e6-b931-acc187320965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-e6ec319d-1782-428c-989c-be25b0f3d501',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1723557972,\n",
       " 'model': '/Users/kevinrvaz/.cache/huggingface/hub/models--TheBloke--Mistral-7B-OpenOrca-GGUF/snapshots/fbd9cd059e5fa0bba72a0abe8aea7e127d7994cb/mistral-7b-openorca.Q4_K_M.gguf',\n",
       " 'choices': [{'text': '\\n\\nIn English:\\n\\n```\\nMy name is Kevin\\n```\\n\\nIn Hindi:\\n\\n```\\nमुझे नाम केविन है\\n```\\n\\nTo get this translation, you can use an online translator like Google Translate or DeepL. Just type or paste the English sentence into the input field, choose the source language (English), and the target language (Hindi). Then click on the \"Translate\" button to get the Hindi translation.\\n\\nPlease note that online translation tools may not always be 100% accurate, so it\\'s always a good idea to have a human check the translation if it\\'s important for your work or study.',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 25, 'completion_tokens': 160, 'total_tokens': 185}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd85936-69b9-401f-b0ea-83f2b59d74b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     3 runs   (    0.01 ms per token, 73170.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1923.10 ms /    39 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:        eval time =     132.30 ms /     2 runs   (   66.15 ms per token,    15.12 tokens per second)\n",
      "llama_print_timings:       total time =    2057.03 ms /    41 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a java code example of using voucherify java sdk version 11.2.2 to create a voucher and also mention documentation of each of the classes used\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459eb5dc-87bf-4b43-ae20-4ed9b40b8a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'.\\n'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5862b2-b58c-43f6-8fd1-c2fcebb76db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /  1000 runs   (    0.01 ms per token, 78746.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     364.86 ms /    11 tokens (   33.17 ms per token,    30.15 tokens per second)\n",
      "llama_print_timings:        eval time =   60251.37 ms /   999 runs   (   60.31 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:       total time =   61322.66 ms /  1010 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain what a binary search tree in data structures is\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "391d0e64-f734-4aaf-a531-d3434158a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.\\n'\n",
      " '\\n'\n",
      " 'A binary search tree (BST) is a type of binary tree used in computer science '\n",
      " 'and data structures where the nodes contain a key, which is an integer or a '\n",
      " 'string that sorts the nodes in a specific way. In a binary search tree, the '\n",
      " 'nodes are arranged in a way that the key in the left subtree of a node is '\n",
      " 'always less than the key of the node itself and the key in the right subtree '\n",
      " 'of the node is always greater than the key of the node itself. This allows '\n",
      " 'for efficient search, insertion, and deletion operations.\\n'\n",
      " '\\n'\n",
      " 'What are the properties of a binary search tree?\\n'\n",
      " '\\n'\n",
      " 'The properties of a binary search tree are as follows:\\n'\n",
      " '\\n'\n",
      " '1. Uniqueness of keys: Each node in a BST has a unique key.\\n'\n",
      " '2. Order: The keys in the left subtree of a node are always less than the '\n",
      " 'key of the node, and the keys in the right subtree of the node are always '\n",
      " 'greater than the key of the node.\\n'\n",
      " '3. Boundary condition: Every node in the tree, except for the root, has a '\n",
      " 'unique predecessor and successor in the tree. The predecessor is the largest '\n",
      " 'node in the left subtree, and the successor is the smallest node in the '\n",
      " 'right subtree.\\n'\n",
      " '4. No duplicate keys: A BST does not allow duplicate keys; if a duplicate '\n",
      " 'key is inserted, it will create an imbalanced tree, leading to inefficiency '\n",
      " 'in search operations.\\n'\n",
      " '\\n'\n",
      " 'How is a binary search tree different from a binary tree?\\n'\n",
      " '\\n'\n",
      " 'A binary search tree (BST) is a specific type of binary tree that is '\n",
      " 'organized in a way that the keys in the left subtree of a node are always '\n",
      " 'less than the key of the node itself, and the keys in the right subtree of '\n",
      " 'the node are always greater than the key of the node itself. This ordering '\n",
      " 'property allows for efficient search, insertion, and deletion operations '\n",
      " 'compared to a generic binary tree, where the nodes do not have any specific '\n",
      " 'ordering.\\n'\n",
      " '\\n'\n",
      " 'What are the time complexities of search, insertion, and deletion operations '\n",
      " 'in a binary search tree?\\n'\n",
      " '\\n'\n",
      " 'The time complexities of search, insertion, and deletion operations in a '\n",
      " 'binary search tree are:\\n'\n",
      " '\\n'\n",
      " '1. Search: The search operation has a time complexity of O(h), where h is '\n",
      " 'the height of the tree. Since the tree is balanced, the average height is '\n",
      " 'logarithmic, so the search operation has an average time complexity of O(log '\n",
      " 'n), where n is the number of nodes in the tree.\\n'\n",
      " '\\n'\n",
      " '2. Insertion: The insertion operation also has a time complexity of O(h), '\n",
      " 'but since the tree is balanced, the average height is logarithmic, so the '\n",
      " 'insertion operation has an average time complexity of O(log n).\\n'\n",
      " '\\n'\n",
      " '3. Deletion: The deletion operation also has a time complexity of O(h), but '\n",
      " 'since the tree is balanced, the average height is logarithmic, so the '\n",
      " 'deletion operation has an average time complexity of O(log n).\\n'\n",
      " '\\n'\n",
      " 'What is the difference between a binary search tree and a red-black tree?\\n'\n",
      " '\\n'\n",
      " 'A binary search tree (BST) is a type of binary tree where the nodes are '\n",
      " 'arranged in a specific order, ensuring efficient search, insertion, and '\n",
      " 'deletion operations. A red-black tree is a specific type of binary search '\n",
      " 'tree that is balanced and self-balancing, ensuring that the height of the '\n",
      " 'tree is logarithmic.\\n'\n",
      " '\\n'\n",
      " 'A red-black tree has the following properties:\\n'\n",
      " '\\n'\n",
      " '1. Each node is colored either red or black.\\n'\n",
      " '2. Every node is either red or black, but not both.\\n'\n",
      " '3. The root of the tree is always black.\\n'\n",
      " '4. Every leaf node (a node with no children) is always black.\\n'\n",
      " '5. If a node is red, then both its children must be black.\\n'\n",
      " '6. The tree is balanced, ensuring that the height of the tree is '\n",
      " 'logarithmic.\\n'\n",
      " '\\n'\n",
      " 'In summary, a binary search tree is a type of binary tree with a specific '\n",
      " 'ordering of keys, while a red-black tree is a balanced and self-balancing '\n",
      " 'binary search tree that ensures logarithmic height.\\n'\n",
      " '\\n'\n",
      " 'What is a binary search tree used for?\\n'\n",
      " '\\n'\n",
      " 'A binary search tree is used in data structures and algorithms to '\n",
      " 'efficiently perform search, insertion, and deletion operations on a '\n",
      " 'collection of data. The ordering of keys in the tree allows for fast search '\n",
      " 'and retrieval of elements, making it useful for various applications such '\n",
      " 'as:\\n'\n",
      " '\\n'\n",
      " '1. Implementation of dictionaries and sets in programming languages.\\n'\n",
      " '2. Efficiently storing and retrieving data in databases.\\n'\n",
      " '3. Efficiently implementing search trees, which can be used in various '\n",
      " 'algorithms and')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86c88f4-a8c5-4c30-91a9-f2f5db09f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /   733 runs   (    0.01 ms per token, 80815.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.17 ms /     7 tokens (   34.02 ms per token,    29.39 tokens per second)\n",
      "llama_print_timings:        eval time =   43901.93 ms /   732 runs   (   59.98 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:       total time =   44561.97 ms /   739 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me some cool team name which works on artificial intelligence\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f59e2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and machine learning.\n",
      "\n",
      "1\n",
      "\n",
      "The Cerebral Coders\n",
      "The name suggests a group of intelligent individuals who are skilled in programming and coding, and also implies a connection to the brain, as in artificial intelligence.\n",
      "\n",
      "2\n",
      "\n",
      "Neural Networkers\n",
      "This name highlights the connection to artificial intelligence and machine learning, as neural networks are a key component in these fields. It also suggests that they are a group of people who are experts in this technology.\n",
      "\n",
      "3\n",
      "\n",
      "Machine Learning Mavericks\n",
      "This name emphasizes the team's expertise in machine learning, and also implies that they are innovative and unconventional thinkers in their approach to this technology.\n",
      "\n",
      "4\n",
      "\n",
      "AI Innovators\n",
      "This name highlights the team's focus on artificial intelligence and suggests that they are at the forefront of innovation in this field.\n",
      "\n",
      "5\n",
      "\n",
      "Cognitive Crew\n",
      "This name suggests that the team is skilled in cognitive computing, a subset of artificial intelligence that deals with simulating human thought processes in computers. It also implies a group of people working together on this technology.\n",
      "\n",
      "6\n",
      "\n",
      "Robo-Wizards\n",
      "This name adds a fun and creative element to the team's expertise in artificial intelligence and machine learning, suggesting that they are skilled in creating and controlling robots and intelligent systems.\n",
      "\n",
      "7\n",
      "\n",
      "Intelligent Automation Architects\n",
      "This name emphasizes the team's focus on designing and implementing automated systems that utilize artificial intelligence and machine learning, showcasing their expertise in this field.\n",
      "\n",
      "8\n",
      "\n",
      "AI & ML Mavens\n",
      "This name combines both artificial intelligence (AI) and machine learning (ML) in the team's expertise, and suggests that they are experts in these fields, or \"mavens.\"\n",
      "\n",
      "9\n",
      "\n",
      "Cognitive Computing Commandos\n",
      "This name adds an adventurous and exciting aspect to the team's expertise in cognitive computing, suggesting that they are skilled in creating and implementing intelligent systems that simulate human thought processes.\n",
      "\n",
      "10\n",
      "\n",
      "Algorist All-Stars\n",
      "This name emphasizes the team's focus on algorithms, a crucial component in artificial intelligence and machine learning, and suggests that they are experts in this field.\n",
      "\n",
      "11\n",
      "\n",
      "NeuroTech Ninjas\n",
      "This name combines the fields of neuroscience and technology, highlighting the team's expertise in developing artificial intelligence and machine learning solutions that are inspired by the brain's processes.\n",
      "\n",
      "12\n",
      "\n",
      "Cybernetic Centurions\n",
      "This name adds a historical and futuristic element to the team's expertise in artificial intelligence and machine learning, suggesting that they are skilled in creating and controlling advanced cybernetic systems.\n",
      "\n",
      "13\n",
      "\n",
      "Intelligent Automation Ingenuity\n",
      "This name highlights the team's ability to innovate and create advanced automated systems that utilize artificial intelligence and machine learning, showcasing their expertise in this field.\n",
      "\n",
      "14\n",
      "\n",
      "Cerebral Coders & AI Alchemists\n",
      "This name combines two aspects of the team's expertise - coding and artificial intelligence - and adds an element of magic and innovation, suggesting that they are skilled in creating intelligent systems through their work.\n",
      "\n",
      "15\n",
      "\n",
      "Machine Learning Mavericks & AI Innovators\n",
      "This name emphasizes the team's expertise in both machine learning and artificial intelligence, and suggests that they are innovative and unconventional thinkers in their approach to these technologies.\n"
     ]
    }
   ],
   "source": [
    "print(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede29c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /   361 runs   (    0.01 ms per token, 83218.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.06 ms /     5 tokens (   38.81 ms per token,    25.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20680.28 ms /   360 runs   (   57.45 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:       total time =   21026.02 ms /   365 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is india?\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70ac0d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "India is the seventh-largest country in the world, located in South Asia, occupying the major part of the Indian subcontinent. It is bordered by Pakistan to the northwest, China, Nepal, and Bhutan to the north, and Bangladesh and Myanmar to the east. The Indian Ocean lies to the south of India, while the Arabian Sea lies to the southwest.\n",
      "\n",
      "India is known for its rich cultural heritage, diverse languages, and a variety of religions, including Hinduism, Islam, Christianity, Sikhism, Buddhism, and Jainism. The country has a long history, with some of the earliest civilizations in the world, such as the Indus Valley Civilization, which dates back to around 3300 BCE.\n",
      "\n",
      "The Indian economy is the world's seventh-largest by nominal GDP and the third-largest by purchasing power parity. India is a federal parliamentary republic, with its capital being New Delhi. The country has a population of over 1.3 billion people, making it the second-most populous nation in the world.\n",
      "\n",
      "India is known for its diverse landscape, including the Himalayan mountain range, the Thar Desert, the Ganges River, and numerous national parks and wildlife sanctuaries. The country is also home to a rich tradition of art, music, dance, and literature, with a history that spans thousands of years.\n",
      "\n",
      "In summary, India is a vast and diverse country with a rich history and cultural heritage. It is known for its unique blend of ancient traditions and modern progress, making it an important and influential nation on the world stage.\n"
     ]
    }
   ],
   "source": [
    "print(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c02532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /  1000 runs   (    0.01 ms per token, 79007.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.06 ms /     4 tokens (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:        eval time =   59557.28 ms /   999 runs   (   59.62 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:       total time =   60436.22 ms /  1003 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is a macbook?\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72a3c1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A macbook is a type of laptop computer made by Apple Inc. These laptops are known for their sleek design, high performance, and user-friendly interface. They run on Apple's macOS operating system, which is designed specifically for Apple hardware. MacBooks are available in various models, such as the MacBook Air, MacBook Pro, and MacBook, each with its own unique features and capabilities.\n",
      "\n",
      "What are the different types of macbook?\n",
      "\n",
      "1. MacBook Air: This is the lightest and most portable MacBook model. It features a thin and lightweight design, long battery life, and an excellent keyboard. The MacBook Air is perfect for users who prioritize portability and need a reliable laptop for everyday tasks and light to moderate workloads.\n",
      "\n",
      "2. MacBook Pro: The MacBook Pro comes in two sizes, 13-inch and 15-inch. These laptops are designed for users who require more power and performance than the MacBook Air can provide. The 13-inch MacBook Pro offers a balance of portability and performance, while the 15-inch model is geared towards users who need even more processing power and advanced features, such as a higher-resolution display and more powerful graphics.\n",
      "\n",
      "3. MacBook: This model is now discontinued, but it was the original MacBook design that was introduced in 2006. It featured a sleek, aluminum design and was known for its lightweight and compact form factor. The MacBook was aimed at users who wanted a high-quality laptop with a focus on portability.\n",
      "\n",
      "What are the main features of a macbook?\n",
      "\n",
      "1. Design: MacBooks are known for their sleek, aluminum designs and thin, lightweight bodies. They are visually appealing and easy to carry around.\n",
      "\n",
      "2. Display: MacBooks offer high-resolution displays, providing sharp and vibrant visuals. The Retina display technology used in newer models offers even higher resolution, resulting in more detailed and lifelike images.\n",
      "\n",
      "3. Performance: MacBooks are known for their powerful processors and efficient performance. They can handle a wide range of tasks, from everyday use to more demanding tasks such as video editing and programming.\n",
      "\n",
      "4. Keyboard: Apple has made improvements to its keyboards over the years, with the latest models featuring a Magic Keyboard that offers a comfortable typing experience and reliable performance.\n",
      "\n",
      "5. Battery life: MacBooks are known for their long battery life, allowing users to work and play for extended periods without needing to recharge.\n",
      "\n",
      "6. Security: macOS is designed to be secure and resistant to malware, providing users with a safer computing experience.\n",
      "\n",
      "7. Ecosystem: MacBooks seamlessly integrate with other Apple products, such as the iPhone and iPad, allowing for a consistent and cohesive user experience across devices.\n",
      "\n",
      "What are the benefits of using a macbook?\n",
      "\n",
      "1. User-friendly interface: MacBooks run on macOS, an intuitive and easy-to-use operating system designed specifically for Apple hardware. This makes it simple for users to navigate and manage their devices.\n",
      "\n",
      "2. Reliability and security: MacBooks are known for their reliability and durability, with fewer issues related to hardware and software compared to other laptop manufacturers. Additionally, macOS is designed to be secure and resistant to malware, providing users with a safer computing experience.\n",
      "\n",
      "3. Integration with other Apple products: MacBooks seamlessly integrate with other Apple devices, such as the iPhone and iPad, making it easy to switch between devices and share data.\n",
      "\n",
      "4. High performance: MacBooks are known for their powerful processors and efficient performance, allowing users to handle a wide range of tasks with ease.\n",
      "\n",
      "5. Excellent customer support and service: Apple offers excellent customer support and service, with both online and physical stores available for assistance and troubleshooting.\n",
      "\n",
      "6. Long battery life: MacBooks are known for their long battery life, allowing users to work and play for extended periods without needing to recharge.\n",
      "\n",
      "What are the disadvantages of using a macbook?\n",
      "\n",
      "1. Cost: MacBooks are generally more expensive than laptops from other manufacturers, which can be a significant factor for users on a budget.\n",
      "\n",
      "2. Limited software options: Some popular software applications may not be available for macOS, requiring users to use alternative solutions or run Windows through Boot Camp or virtualization software.\n",
      "\n",
      "3. Limited hardware customization: MacBooks typically come with a limited selection of hardware options, which may not be suitable for users with specific performance requirements.\n"
     ]
    }
   ],
   "source": [
    "print(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfba7f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5040.26 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /   616 runs   (    0.01 ms per token, 79989.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.97 ms /     7 tokens (   41.42 ms per token,    24.14 tokens per second)\n",
      "llama_print_timings:        eval time =   36196.01 ms /   615 runs   (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:       total time =   36800.57 ms /   622 tokens\n"
     ]
    }
   ],
   "source": [
    "prompt = \"tell me a good cake recipe?\"\n",
    "res = llm(prompt, **generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10904877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A good cake recipe is one that yields a moist, flavorful, and delicious cake that is easy to make and can be enjoyed by everyone. Here is a simple and delicious chocolate cake recipe that is perfect for any occasion:\n",
      "\n",
      "Ingredients:\n",
      "- 2 cups granulated sugar\n",
      "- 1-3/4 cups all-purpose flour\n",
      "- 3/4 cup unsweetened cocoa powder (natural or Dutch-process)\n",
      "- 1-1/2 teaspoons baking powder\n",
      "- 1-1/2 teaspoons baking soda\n",
      "- 1 teaspoon salt\n",
      "- 2 large eggs\n",
      "- 1 cup whole milk\n",
      "- 1/2 cup vegetable oil\n",
      "- 2 teaspoons pure vanilla extract\n",
      "- 1 cup boiling water\n",
      "\n",
      "For the frosting:\n",
      "- 1/2 cup unsalted butter, softened\n",
      "- 2 cups powdered sugar\n",
      "- 1/4 cup unsweetened cocoa powder\n",
      "- 2 tablespoons whole milk\n",
      "- 1 teaspoon pure vanilla extract\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 350°F (175°C). Grease and flour two 9-inch round cake pans.\n",
      "\n",
      "2. In a large mixing bowl, whisk together the sugar, flour, cocoa powder, baking powder, baking soda, and salt.\n",
      "\n",
      "3. In a separate bowl, whisk together the eggs, milk, vegetable oil, and vanilla extract.\n",
      "\n",
      "4. Slowly pour the wet ingredients into the dry ingredients, and mix until just combined. Be careful not to overmix.\n",
      "\n",
      "5. Stir in the boiling water, and mix until smooth. The batter will be thin.\n",
      "\n",
      "6. Pour the batter into the prepared cake pans, dividing it evenly.\n",
      "\n",
      "7. Bake for 25-30 minutes, or until a toothpick inserted in the center of the cake comes out clean.\n",
      "\n",
      "8. Allow the cakes to cool in the pans for 15-20 minutes before transferring them to a wire rack to cool completely.\n",
      "\n",
      "9. To make the frosting, beat the softened butter in a bowl until creamy. Gradually add the powdered sugar, cocoa powder, milk, and vanilla extract, mixing well after each addition.\n",
      "\n",
      "10. Once the cakes have cooled completely, spread the frosting evenly on top of the first cake layer, then place the second layer on top. Frost the top and sides of the cake with the remaining frosting.\n",
      "\n",
      "11. Enjoy your delicious chocolate cake!\n",
      "\n",
      "This recipe is simple, easy to make, and produces a moist and flavorful chocolate cake that is sure to be a hit at any gathering.\n"
     ]
    }
   ],
   "source": [
    "print(res['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69e0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
